{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2024/05/20 グリッドサーチを行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶ライブラリを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import io\n",
    "import math\n",
    "import copy\n",
    "from scipy.stats import gmean\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "from pipeline_functions import PipelineFunctions\n",
    "pf = PipelineFunctions()\n",
    "from view_functions import ViewFunctions\n",
    "vf = ViewFunctions()\n",
    "\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "palette = ['#CC521D', '#4F4AD7', '#39AE3D']\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_CNT = 5\n",
    "data = pd.read_pickle(f'../data/data_unify_ptcnt/ptcnt_{PT_CNT}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶特徴量を導出用関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元座標を結合\n",
    "def calc_org_coord(x, y):\n",
    "    return x + y\n",
    "\n",
    "# 線分のベクトルを結合\n",
    "def calc_segment_vec(x, y):\n",
    "    return [x[i]-x[i-1] for i in range(1, len(x))] + [y[i]-y[i-1] for i in range(1, len(x))]\n",
    "\n",
    "# 線分のベクトルどうしのコサイン類似度\n",
    "def calc_segment_cossim(x, y):\n",
    "    def calc_cos_sim(v1, v2):\n",
    "        if (np.linalg.norm(v1) * np.linalg.norm(v2)) == 0:\n",
    "            print('------------ exception segment -------------')\n",
    "            return 1\n",
    "        else:\n",
    "            return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    cos_sim = [calc_cos_sim(np.array([x[i]-x[i-1], y[i]-y[i-1]]), \n",
    "                            np.array([x[i-1]-x[i-2], y[i-1]-y[i-2]])) for i in range(2, len(x))]\n",
    "    return cos_sim\n",
    "\n",
    "# 線分のベクトルと始点終点間ベクトルのコサイン類似度\n",
    "def calc_startend_seg_cossim(x, y):\n",
    "    def calc_cos_sim(v1, v2):\n",
    "        if (np.linalg.norm(v1) * np.linalg.norm(v2)) == 0:\n",
    "            print('------------ exception startend -------------')\n",
    "            return 1\n",
    "        else:\n",
    "            return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    startend_vec = np.array([x[-1] - x[0], y[-1] - y[0]])\n",
    "    vec_x = [x[i]-x[i-1] for i in range(1, len(x))]\n",
    "    vec_y = [y[i]-y[i-1] for i in range(1, len(y))]\n",
    "    cos_sim = [calc_cos_sim(startend_vec, np.array([vecx, vecy])) for vecx, vecy in zip(vec_x, vec_y)]\n",
    "    return cos_sim\n",
    "\n",
    "# 点上での勾配ベクトルと始点終点間ベクトルのコサイン類似度\n",
    "def calc_startend_grad_cossim(x, y, grad_x, grad_y):\n",
    "    def calc_cos_sim(v1, v2):\n",
    "        if (np.linalg.norm(v1) * np.linalg.norm(v2)) == 0:\n",
    "            print('------------ exception gradient-------------')\n",
    "            return 1\n",
    "        else:\n",
    "            return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    startend_vec = np.array([x[-1] - x[0], y[-1] - y[0]])\n",
    "    cos_sim = [calc_cos_sim(startend_vec, np.array([vec_x, vec_y])) for vec_x, vec_y in zip(grad_x, grad_y)]\n",
    "    return cos_sim\n",
    "\n",
    "def calc_segment_grad_cossim(grad_x, grad_y):\n",
    "    def calc_cos_sim(v1, v2):\n",
    "        if (np.linalg.norm(v1) * np.linalg.norm(v2)) == 0:\n",
    "            print('------------ exception segment -------------')\n",
    "            return 1\n",
    "        else:\n",
    "            return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    cos_sim = [calc_cos_sim(np.array([grad_x[i-1], grad_y[i-1]]), \n",
    "                            np.array([grad_x[i], grad_y[i]])) for i in range(1, len(grad_x))]\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶ 座標数の揃え方ごとで特徴量を導出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTCNT_COORD_INTERVAL = ['equal_coord_intervel_x', 'equal_coord_intervel_y']\n",
    "PTCNT_SMALLER_COSSIM = ['smaller_cossim_x', 'smaller_cossim_y']\n",
    "PTCNT_LEN_INTERVAL = ['equal_interval_x', 'equal_interval_y']\n",
    "PTCNT_LEN_INTERVAL_GRAD = ['equal_interval_vecx', 'equal_interval_vecy']\n",
    "PTCNT = [PTCNT_COORD_INTERVAL, PTCNT_SMALLER_COSSIM, PTCNT_LEN_INTERVAL, PTCNT_LEN_INTERVAL_GRAD]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶　座票数（3~83個）と座標数の揃え方（3種類）の組み合わせでファイルを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  |  2\n",
      "4  |  2\n",
      "5  |  2\n",
      "6  |  2\n",
      "7  |  2\n",
      "8  |  2\n",
      "9  |  2\n",
      "10  |  2\n",
      "11  |  2\n",
      "12  |  2\n",
      "13  |  2\n",
      "14  |  2\n",
      "15  |  2\n",
      "16  |  2\n",
      "17  |  2\n",
      "18  |  2\n",
      "19  |  2\n",
      "20  |  2\n",
      "21  |  2\n",
      "22  |  2\n",
      "23  |  2\n",
      "24  |  2\n",
      "25  |  2\n",
      "26  |  2\n",
      "27  |  2\n",
      "28  |  2\n",
      "29  |  2\n",
      "30  |  2\n",
      "31  |  2\n",
      "32  |  2\n",
      "33  |  2\n",
      "34  |  2\n",
      "35  |  2\n",
      "36  |  2\n",
      "37  |  2\n",
      "38  |  2\n",
      "39  |  2\n",
      "40  |  2\n",
      "41  |  2\n",
      "42  |  2\n",
      "43  |  2\n",
      "44  |  2\n",
      "45  |  2\n",
      "46  |  2\n",
      "47  |  2\n",
      "48  |  2\n",
      "49  |  2\n",
      "50  |  2\n",
      "51  |  2\n",
      "52  |  2\n",
      "53  |  2\n",
      "54  |  2\n",
      "55  |  2\n",
      "56  |  2\n",
      "57  |  2\n",
      "58  |  2\n",
      "59  |  2\n",
      "60  |  2\n",
      "61  |  2\n",
      "62  |  2\n",
      "63  |  2\n",
      "64  |  2\n",
      "65  |  2\n",
      "66  |  2\n",
      "67  |  2\n",
      "68  |  2\n",
      "69  |  2\n",
      "70  |  2\n",
      "71  |  2\n",
      "72  |  2\n",
      "73  |  2\n",
      "74  |  2\n",
      "75  |  2\n",
      "76  |  2\n",
      "77  |  2\n",
      "78  |  2\n",
      "79  |  2\n",
      "80  |  2\n",
      "81  |  2\n",
      "82  |  2\n",
      "83  |  2\n"
     ]
    }
   ],
   "source": [
    "for pt_cnt in range(3, 84):\n",
    "    data = pd.read_pickle(f'../data/data_unify_ptcnt/ptcnt_{pt_cnt}.pkl')\n",
    "    ptcnt_type = 2\n",
    "    copy_data = data.copy()\n",
    "    org_coord = [calc_org_coord(x, y) for x, y in zip(data[PTCNT[ptcnt_type][0]], data[PTCNT[ptcnt_type][1]])]\n",
    "    segment_vec  = [calc_segment_vec(x, y) for x, y in zip(data[PTCNT[ptcnt_type][0]], data[PTCNT[ptcnt_type][1]])]\n",
    "    segment_cossim  = [calc_segment_cossim(x, y) for x, y in zip(data[PTCNT[ptcnt_type][0]], data[PTCNT[ptcnt_type][1]])]\n",
    "    startend_seg_cossim = [calc_startend_seg_cossim(x, y) for x, y in zip(data[PTCNT[ptcnt_type][0]], data[PTCNT[ptcnt_type][1]])]\n",
    "    feature = pd.DataFrame({\n",
    "        'org_coord': org_coord,\n",
    "        'segment_vec': segment_vec,\n",
    "        'segment_cossim': segment_cossim,\n",
    "        'startend_seg_cossim': startend_seg_cossim\n",
    "    })\n",
    "    \n",
    "    startend_grad_cossim = [calc_startend_grad_cossim(x, y, grad_x, grad_y) for x, y, grad_x, grad_y in zip(\n",
    "        data['equal_interval_x'], data['equal_interval_y'], data['equal_interval_vecx'], data['equal_interval_vecy'])]\n",
    "    \n",
    "    segment_grad_cossim = [calc_segment_grad_cossim(grad_x, grad_y) for grad_x, grad_y in zip(\n",
    "        data['equal_interval_vecx'], data['equal_interval_vecy'])]\n",
    "    \n",
    "    feature = pd.DataFrame({\n",
    "        'segment_grad_cossim': segment_grad_cossim,\n",
    "        'startend_grad_cossim': startend_grad_cossim\n",
    "    })\n",
    "    \n",
    "    data_ptcnt_feature = pd.concat([copy_data, feature], axis=1)\n",
    "    data_ptcnt_feature.to_pickle(f'../temp/grad_feature/{ptcnt_type}_{pt_cnt}.pkl')\n",
    "    print(pt_cnt, ' | ', ptcnt_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶特徴点ごとに列を分けたcsvファイルを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_cols = ['segment_grad_cossim', 'startend_grad_cossim']\n",
    "# for pt_cnt in range(3, 84):\n",
    "#     ptcnt_type = 2\n",
    "#     data = pd.read_pickle(f'../temp/grad_feature/{ptcnt_type}_{pt_cnt}.pkl')\n",
    "#     for X_col in X_cols:\n",
    "#         eachpt_feature = {}\n",
    "#         eachpt_feature['drawing_id'] = data['drawing_id']\n",
    "#         eachpt_feature['stroke_id'] = data['stroke_id']\n",
    "#         eachpt_feature['saito_label'] = data['saito_label']\n",
    "#         eachpt_feature['is_good_saito'] = data['is_good_saito']\n",
    "#         eachpt_feature['is_good_rulebase'] = data['is_good_rulebase']\n",
    "#         for i in range(len(data[X_col].iloc[-1])):\n",
    "#             eachpt_feature[f'feature_{i}'] = [vals[i] for vals in data[X_col]]\n",
    "#         df_eachpt_feature = pd.DataFrame(eachpt_feature)\n",
    "#         file_name = f'../temp/eachpt_feature_grad/{ptcnt_type}_{pt_cnt}_{X_col}.csv'\n",
    "#         df_eachpt_feature.to_csv(file_name)\n",
    "#         print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶検証を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def grid_search_svm(train_valid, test, X_col, kernel, c, gamma, degree):\n",
    "    K = 5\n",
    "    KFOLD_SEED = 1\n",
    "    SHUFFLE_LABEL = 'saito_label'\n",
    "    \n",
    "    # 学習データと検証データ：入力する特徴量を各特徴点で分ける\n",
    "    dict_feature_pt_col = {}\n",
    "    dict_feature_pt_col['drawing_id'] = train_valid['drawing_id']\n",
    "    dict_feature_pt_col['stroke_id'] = train_valid['stroke_id']\n",
    "    for i in range(len(train_valid[X_col].iloc[-1])):\n",
    "        dict_feature_pt_col[f'feature_{i}'] = [vals[i] for vals in train_valid[X_col]]\n",
    "    feature_pt = pd.DataFrame(dict_feature_pt_col)\n",
    "    train_valid = pd.concat([train_valid.copy(), feature_pt], axis=1)    \n",
    "    \n",
    "    # テストデータ：入力する特徴量を各特徴点で分ける\n",
    "    dict_feature_pt_col_test = {}\n",
    "    dict_feature_pt_col_test['drawing_id'] = test['drawing_id']\n",
    "    dict_feature_pt_col_test['stroke_id'] = test['stroke_id']\n",
    "    for i in range(len(test[X_col].iloc[-1])):\n",
    "        dict_feature_pt_col_test[f'feature_{i}'] = [vals[i] for vals in test[X_col]]\n",
    "    feature_pt_test = pd.DataFrame(dict_feature_pt_col_test)\n",
    "    test = pd.concat([test.copy(), feature_pt_test], axis=1)\n",
    "\n",
    "    # K-Fold\n",
    "    skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=KFOLD_SEED)\n",
    "    for i, (train_index, valid_index) in enumerate(skf.split(train_valid, train_valid[SHUFFLE_LABEL])):\n",
    "        \n",
    "        # 訓練データと検証データに分ける\n",
    "        train, valid = train_valid.iloc[train_index], train_valid.iloc[valid_index]\n",
    "        \n",
    "        # 説明変数と目的変数に分ける\n",
    "        X_pt_col = [col for col in train_valid if 'feature_' in col]\n",
    "        y_col = 'saito_label'\n",
    "        train_X = train.copy()[X_pt_col]\n",
    "        train_y = train.copy()[y_col]\n",
    "        valid_X = valid.copy()[X_pt_col]\n",
    "        valid_y = valid.copy()[y_col]\n",
    "\n",
    "        test_X = test.copy()[X_pt_col]\n",
    "        test_y = test.copy()[y_col]\n",
    "        \n",
    "        # 学習データのスケーリング(正規化, 学習データのmin, maxを検証データとテストデータに適用)\n",
    "        scaler = MinMaxScaler()\n",
    "        for col in train_X:\n",
    "            train_minmax = scaler.fit(train[[col]])\n",
    "            train_X[f'norm_{col}'] = scaler.transform(train[[col]])\n",
    "            valid_X[f'norm_{col}'] = scaler.transform(valid[[col]])\n",
    "            test_X[f'norm_{col}'] = scaler.transform(test[[col]])\n",
    "            del train_X[col]\n",
    "            del valid_X[col]\n",
    "            del test_X[col]\n",
    "        \n",
    "        # モデルへの入力形式に変換する\n",
    "        train_X = train_X.to_numpy()\n",
    "        train_y = train_y.to_numpy()\n",
    "        valid_X = valid_X.to_numpy()\n",
    "        valid_y = valid_y.to_numpy()\n",
    "        test_X = test_X.to_numpy()\n",
    "        test_y = test_y.to_numpy()\n",
    "        \n",
    "        # モデルを生成する\n",
    "        svm_model = SVC(kernel=kernel, C=c, gamma=gamma, degree=degree)\n",
    "        # モデルを学習させる\n",
    "        svm_result = svm_model.fit(train_X, train_y)\n",
    "        # 検証データで精度を算出する\n",
    "        svm_valid = svm_model.predict(valid_X)\n",
    "        recall = recall_score(valid_y, svm_valid, average=None)[1]\n",
    "        precision = precision_score(valid_y, svm_valid, average=None)[1]\n",
    "        f1 = f1_score(valid_y, svm_valid, average=None)[1]\n",
    "        accuracy = accuracy_score(valid_y, svm_valid)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    # 学習+検証データで学習し, テストデータで精度を算出する\n",
    "    # 説明変数と目的変数に分ける\n",
    "    X_pt_col = [col for col in train_valid if 'feature_' in col]\n",
    "    y_col = 'saito_label'\n",
    "    train_X = train_valid.copy()[X_pt_col]\n",
    "    train_y = train_valid.copy()[y_col]\n",
    "    \n",
    "    test_X = test.copy()[X_pt_col]\n",
    "    test_y = test.copy()[y_col]\n",
    "\n",
    "    # 学習データのスケーリング(正規化, 学習データのmin, maxを検証データとテストデータに適用)\n",
    "    scaler = MinMaxScaler()\n",
    "    for col in train_X:\n",
    "        train_minmax = scaler.fit(train_valid[[col]])\n",
    "        train_X[f'norm_{col}'] = scaler.transform(train_valid[[col]])\n",
    "        test_X[f'norm_{col}'] = scaler.transform(test[[col]])\n",
    "        del train_X[col]\n",
    "        del test_X[col]\n",
    "        \n",
    "    # モデルへの入力形式に変換する\n",
    "    train_X = train_X.to_numpy()\n",
    "    train_y = train_y.to_numpy()\n",
    "    test_X = test_X.to_numpy()\n",
    "    test_y = test_y.to_numpy()\n",
    "    \n",
    "    # モデルを生成する\n",
    "    svm_model = SVC(kernel=kernel, C=c, gamma=gamma, degree=degree)\n",
    "    # モデルを学習させる\n",
    "    svm_result = svm_model.fit(train_X, train_y)\n",
    "    # 検証データで精度を算出する\n",
    "    svm_test = svm_model.predict(test_X)\n",
    "    recall = recall_score(test_y, svm_test, average=None)[1]\n",
    "    precision = precision_score(test_y, svm_test, average=None)[1]\n",
    "    f1 = f1_score(test_y, svm_test, average=None)[1]\n",
    "    accuracy = accuracy_score(test_y, svm_test)\n",
    "    \n",
    "    print(recall)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変えないパラメータ\n",
    "TRAIN_TEST_SPLIT_SEED = 1\n",
    "Y_COL = 'saito_label'\n",
    "\n",
    "# 変えるパラメータ\n",
    "PTCNT = [i for i in range(3, 84)]\n",
    "PTCNT_TYPE = [1, 2]\n",
    "X_COL = ['org_coord', 'segment_vec', 'segment_cossim', 'startend_seg_cossim']\n",
    "SVM_PARAMETER = pd.read_csv('../temp/svm_parameter.csv', delimiter=',', index_col=0)\n",
    "\n",
    "# 各組み合わせごとにモデルを作成し検証\n",
    "for ptcnt_type in PTCNT_TYPE:\n",
    "    for ptcnt in PTCNT:\n",
    "        data = pd.read_pickle(f'../data/data_ptcnt_feature_combo/{ptcnt_type}_{ptcnt}.pkl')\n",
    "        X = data.copy()\n",
    "        y = data[Y_COL]\n",
    "        # 学習データとテストデータを725:310に分割する\n",
    "        train, test, y_train, y_test = train_test_split(\n",
    "            X, y, train_size=725, shuffle=True, random_state=TRAIN_TEST_SPLIT_SEED, stratify=y)\n",
    "        \n",
    "        for X_col in X_COL:\n",
    "            for i, row in SVM_PARAMETER.iterrows():\n",
    "\n",
    "                grid_search_svm(train, test, X_col, row['kernel'], row['c'], row['gamma'], row['degree'])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶▶SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# ハイパーパラメータ #\n",
    "svm_parameter = {\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'c': [1, 5, 20, 100],\n",
    "    'gamma': ['auto', 'scale', 0.1, 0.5, 1.0, 5.0, 20.0],\n",
    "    'degree': [1, 3, 5, 10],\n",
    "}\n",
    "\n",
    "\n",
    "INPUT_COL = 'equal_interval_vecx'\n",
    "K = 5\n",
    "SHUFFLE_LABEL = 'saito_label'\n",
    "SHUFFLE_SEED = 1\n",
    "Y_COL = 'is_good_saito'\n",
    "SVM_SEED = 1\n",
    "###############################################\n",
    "\n",
    "# 入力する特徴量を各特徴点で分ける\n",
    "dict_feature_pt_col = {}\n",
    "for i in range(len(features[INPUT_COL][0])):\n",
    "    dict_feature_pt_col[f'feature_{i}'] = [vals[i] for vals in features[INPUT_COL]]\n",
    "input_feature = pd.DataFrame(dict_feature_pt_col)\n",
    "\n",
    "data_featurepts = pd.concat([data.copy(), input_feature.copy()], axis=1)\n",
    "\n",
    "###############################################\n",
    "\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=SEED)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(data_featurepts, data_featurepts[SHUFFLE_LABEL])):\n",
    "    # 訓練データとテストデータに分ける\n",
    "    train, test = data_featurepts.iloc[train_index], data_featurepts.iloc[test_index]\n",
    "    \n",
    "    # 説明変数と目的変数に分ける\n",
    "    X_COL = [col for col in data_featurepts if 'feature_' in col]\n",
    "    train_X = train.copy()[X_COL]\n",
    "    train_y = train.copy()[Y_COL]\n",
    "    test_X = test.copy()[X_COL]\n",
    "    test_y = test.copy()[Y_COL]\n",
    "    \n",
    "    # スケーリング\n",
    "    scaler = MinMaxScaler()\n",
    "    for col in train_X:\n",
    "        train_X[f'norm_{col}'] = scaler.fit_transform(train[[col]])\n",
    "        del train_X[col]\n",
    "    \n",
    "    # モデルへの入力形式に変換する\n",
    "    train_X = train_X.to_numpy()\n",
    "    train_y = train_y.to_numpy()\n",
    "    test_X = test_X.to_numpy()\n",
    "    test_y = test_y.to_numpy()\n",
    "    \n",
    "    # モデルに入力する\n",
    "    svm_model = SVC(kernel='rbf', gamma='auto', random_state=SVM_SEED)\n",
    "    svm_result = svm_model.fit(train_X, train_y)\n",
    "    svm_pred = svm_model.predict(test_X)\n",
    "    print(confusion_matrix(test_y, svm_pred))\n",
    "    print(classification_report(test_y, svm_pred))\n",
    "    \n",
    "    print('##########################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶ハイパーパラメータを組み合わせたdfを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶▶SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# ハイパーパラメータ #\n",
    "svm_parameter = {\n",
    "    'kernel': ['rbf'],\n",
    "    'c': [1, 5, 20, 100],\n",
    "    'gamma': [0.01, 0.1, 0.5, 1.0, 5.0, 20.0],\n",
    "    'degree': [1],\n",
    "}\n",
    "#####################\n",
    "kernels = []\n",
    "cs = []\n",
    "gammas = []\n",
    "degrees = []\n",
    "\n",
    "for kernel in svm_parameter['kernel']:\n",
    "    for c in svm_parameter['c']:\n",
    "        for gamma in svm_parameter['gamma']:\n",
    "            for degree in svm_parameter['degree']:\n",
    "                kernels.append(kernel)\n",
    "                cs.append(c)\n",
    "                gammas.append(gamma)\n",
    "                degrees.append(degree)\n",
    "\n",
    "svm_parameter_combo = pd.DataFrame({\n",
    "    'kernel': kernels,\n",
    "    'c': cs,\n",
    "    'gamma': gammas,\n",
    "    'degree': degrees\n",
    "})\n",
    "\n",
    "svm_parameter_combo.to_csv('../temp/svm_parameter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../temp/svm_parameter.csv', delimiter=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>gamma</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rbf</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbf</td>\n",
       "      <td>5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rbf</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rbf</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rbf</td>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rbf</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel    c  gamma  degree\n",
       "0     rbf    1    0.5       1\n",
       "1     rbf    1    1.0       1\n",
       "2     rbf    1    5.0       1\n",
       "3     rbf    1   20.0       1\n",
       "4     rbf    5    0.5       1\n",
       "5     rbf    5    1.0       1\n",
       "6     rbf    5    5.0       1\n",
       "7     rbf    5   20.0       1\n",
       "8     rbf   20    0.5       1\n",
       "9     rbf   20    1.0       1\n",
       "10    rbf   20    5.0       1\n",
       "11    rbf   20   20.0       1\n",
       "12    rbf  100    0.5       1\n",
       "13    rbf  100    1.0       1\n",
       "14    rbf  100    5.0       1\n",
       "15    rbf  100   20.0       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ▶svm 1回行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 変えるパラメータ ###\n",
    "PTCNT_TYPE = [1, 2]\n",
    "PTCNT = [i for i in range(3, 84)]\n",
    "X_COL = ['org_coord', 'segment_vec', 'segment_cossim', 'startend_seg_cossim']\n",
    "\n",
    "ptcnt_types = []\n",
    "ptcnts = []\n",
    "X_cols = []\n",
    "for ptcnt_type in PTCNT_TYPE:\n",
    "    for ptcnt in PTCNT:\n",
    "        for X_col in X_COL:\n",
    "            # data = pd.read_csv(f'../temp/eachpt_feature/{ptcnt_type}_{ptcnt}_{X_col}.csv', delimiter=',', index_col=0)\n",
    "            # X = data.copy()\n",
    "            # y = data[Y_COL]\n",
    "            # # 学習データとテストデータを725:310に分割する\n",
    "            # train_valid, test, y_train_valid, y_test = train_test_split(X, y, train_size=725, shuffle=True, stratify=y, random_state=TRAIN_TEST_SPLIT_SEED)\n",
    "            \n",
    "            ptcnt_types.append(ptcnt_type)\n",
    "            ptcnts.append(ptcnt)\n",
    "            X_cols.append(X_col)\n",
    "            \n",
    "param_combo = pd.DataFrame({\n",
    "    'ptcnt_type': ptcnt_types,\n",
    "    'ptcnt': ptcnts,\n",
    "    'X_col': X_cols\n",
    "})\n",
    "param_combo.to_csv('../temp/param_conbo.csv')\n",
    "\n",
    "\n",
    "ptcnt_types = []\n",
    "ptcnts = []\n",
    "X_cols = []\n",
    "X_COL_GRAD = ['segment_grad_cossim', 'startend_grad_cossim']\n",
    "for ptcnt in PTCNT:\n",
    "    for X_col in X_COL_GRAD:        \n",
    "        ptcnt_types.append(2)\n",
    "        ptcnts.append(ptcnt)\n",
    "        X_cols.append(X_col)\n",
    "\n",
    "param_combo_grad = pd.DataFrame({\n",
    "    'ptcnt_type': ptcnt_types,\n",
    "    'ptcnt': ptcnts,\n",
    "    'X_col': X_cols\n",
    "})\n",
    "param_combo_grad.to_csv('../temp/param_conbo_grad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6275862068965518\n",
      "0.6275862068965518\n",
      "0.6206896551724138\n",
      "0.6206896551724138\n",
      "0.6275862068965518\n",
      "0.6225806451612903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ispec\\MyWorkSpace\\python\\drawing_2024\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ispec\\MyWorkSpace\\python\\drawing_2024\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ispec\\MyWorkSpace\\python\\drawing_2024\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ispec\\MyWorkSpace\\python\\drawing_2024\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ispec\\MyWorkSpace\\python\\drawing_2024\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ispec\\MyWorkSpace\\python\\drawing_2024\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "### 変えないパラメータ ###\n",
    "TRAIN_TEST_SPLIT_SEED = 1\n",
    "KFOLD_SHUFFLE_SEED = 1\n",
    "KFOLD_SHUFFLE_LABEL = 'saito_label'\n",
    "Y_COL = 'is_good_saito'\n",
    "K = 5\n",
    "\n",
    "### 変えるパラメータ ###\n",
    "PTCNT_TYPE = [1, 2]\n",
    "PTCNT = [i for i in range(3, 84)]\n",
    "X_COL = ['org_coord', 'segment_vec', 'segment_cossim', 'startend_seg_cossim']\n",
    "\n",
    "### ハイパーパラメータ ###\n",
    "kernel = 'rbf'\n",
    "c = 1\n",
    "gamma = 0.1\n",
    "degree = 3\n",
    "#########################\n",
    "num = 0\n",
    "\n",
    "ptcnt_types = []\n",
    "ptcnts = []\n",
    "X_cols = []\n",
    "for ptcnt_type in PTCNT_TYPE:\n",
    "    for ptcnt in PTCNT:\n",
    "        for X_col in X_COL:\n",
    "            # data = pd.read_csv(f'../temp/eachpt_feature/{ptcnt_type}_{ptcnt}_{X_col}.csv', delimiter=',', index_col=0)\n",
    "            # X = data.copy()\n",
    "            # y = data[Y_COL]\n",
    "            # # 学習データとテストデータを725:310に分割する\n",
    "            # train_valid, test, y_train_valid, y_test = train_test_split(X, y, train_size=725, shuffle=True, stratify=y, random_state=TRAIN_TEST_SPLIT_SEED)\n",
    "            \n",
    "            ptcnt_types.append(ptcnt_type)\n",
    "            ptcnts.append(ptcnt)\n",
    "            X_cols.append(X_col)\n",
    "            \n",
    "param_combo = pd.DataFrame({\n",
    "    'ptcnt_type': ptcnt_types,\n",
    "    'ptcnt': ptcnts,\n",
    "    'X_col': X_cols\n",
    "})\n",
    "param_combo.to_csv('../temp/param_conbo.csv')\n",
    "\n",
    "\n",
    "ptcnt_types = []\n",
    "ptcnts = []\n",
    "X_cols = []\n",
    "X_COL_GRAD = ['segment_grad_cossim', 'startend_grad_cossim']\n",
    "for ptcnt in PTCNT:\n",
    "    for X_col in X_COL_GRAD:        \n",
    "        ptcnt_types.append(2)\n",
    "        ptcnts.append(ptcnt)\n",
    "        X_cols.append(X_col)\n",
    "\n",
    "param_combo_grad = pd.DataFrame({\n",
    "    'ptcnt_type': ptcnt_types,\n",
    "    'ptcnt': ptcnts,\n",
    "    'X_col': X_cols\n",
    "})\n",
    "param_combo_grad.to_csv('../temp/param_conbo_grad.csv')    \n",
    "\n",
    "# K-Fold\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=KFOLD_SHUFFLE_SEED)\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(train_valid, train_valid[KFOLD_SHUFFLE_LABEL])):\n",
    "    \n",
    "    ### 訓練データと検証データに分ける ###\n",
    "    train, valid = train_valid.iloc[train_index], train_valid.iloc[valid_index]\n",
    "    \n",
    "    ### 説明変数と目的変数に分ける ###\n",
    "    X_col = [col for col in train_valid if 'feature_' in col]\n",
    "    y_col = 'is_good_saito'\n",
    "    train_X = train.copy()[X_col]\n",
    "    train_y = train.copy()[y_col]\n",
    "    valid_X = valid.copy()[X_col]\n",
    "    valid_y = valid.copy()[y_col]\n",
    "    \n",
    "    ### 学習データのスケーリング(正規化, 学習データのmin, maxを検証データとテストデータに適用) ###\n",
    "    scaler = MinMaxScaler()\n",
    "    for col in train_X:\n",
    "        train_minmax = scaler.fit(train_X[[col]])\n",
    "        train_X[f'norm_{col}'] = scaler.transform(train_X[[col]])\n",
    "        valid_X[f'norm_{col}'] = scaler.transform(valid_X[[col]])\n",
    "        del train_X[col]\n",
    "        del valid_X[col]\n",
    "    \n",
    "    ### モデルへの入力形式に変換する ###\n",
    "    train_X = train_X.to_numpy()\n",
    "    train_y = train_y.to_numpy()\n",
    "    valid_X = valid_X.to_numpy()\n",
    "    valid_y = valid_y.to_numpy()\n",
    "    \n",
    "    ### モデルを生成する ###\n",
    "    model = SVC(kernel=kernel, C=c, gamma=gamma, degree=degree)\n",
    "    ### モデルを学習させる ###\n",
    "    result = model.fit(train_X, train_y)\n",
    "    ### 検証データで精度を算出する ###\n",
    "    valid_pred = model.predict(valid_X)\n",
    "    ### 各指標の値(validationデータに対する) ###\n",
    "    recall = recall_score(valid_y, valid_pred, average=None)[1]\n",
    "    precision = precision_score(valid_y, valid_pred, average=None)[1]\n",
    "    f1 = f1_score(valid_y, valid_pred, average=None)[1]\n",
    "    accuracy = accuracy_score(valid_y, valid_pred)\n",
    "    print(precision)\n",
    "\n",
    "### 説明変数と目的変数に分ける ###\n",
    "X_col = [col for col in train_valid if 'feature_' in col]\n",
    "y_col = 'is_good_saito'\n",
    "train_valid_X = train_valid.copy()[X_col]\n",
    "train_valid_y = train_valid.copy()[y_col]\n",
    "test_X = test.copy()[X_col]\n",
    "test_y = test.copy()[y_col]\n",
    "\n",
    "### 学習データのスケーリング(正規化, 学習データのmin, maxを検証データとテストデータに適用) ###\n",
    "scaler = MinMaxScaler()\n",
    "for col in train_valid_X:\n",
    "    train_minmax = scaler.fit(train_valid_X[[col]])\n",
    "    train_valid_X[f'norm_{col}'] = scaler.transform(train_valid_X[[col]])\n",
    "    test_X[f'norm_{col}'] = scaler.transform(test_X[[col]])\n",
    "    del train_valid_X[col]\n",
    "    del test_X[col]\n",
    "    \n",
    "### モデルへの入力形式に変換する ###\n",
    "train_valid_X = train_valid_X.to_numpy()\n",
    "train_valid_y = train_valid_y.to_numpy()\n",
    "test_X = test_X.to_numpy()\n",
    "test_y = test_y.to_numpy()\n",
    "\n",
    "### モデルを生成する ###\n",
    "model = SVC(kernel=kernel, C=c, gamma=gamma, degree=degree)\n",
    "### モデルを学習させる ###\n",
    "result = model.fit(train_X, train_y)\n",
    "### 検証データで精度を算出する ###\n",
    "test_pred = model.predict(test_X)\n",
    "### 各指標の値(testデータに対する) ###\n",
    "recall = recall_score(test_y, test_pred, average=None)[1]\n",
    "precision = precision_score(test_y, test_pred, average=None)[1]\n",
    "f1 = f1_score(test_y, test_pred, average=None)[1]\n",
    "accuracy = accuracy_score(test_y, test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
